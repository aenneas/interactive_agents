r2d2_meta_learning_linguistic_5_64_tune:
  stop:
      iterations: 2000
  trainer: independent
  num_seeds: 4
  config:
    max_steps: 200
    iteration_episodes: 32
    eval_iterations: 40
    eval_episodes: 64
    env: linguistic
    env_config:
      stages: 64
      actions: 5
      meta_learning: True
    learner: R2D2
    learner_config:
      num_batches: 16
      batch_size: 32
      sync_iterations:
        grid_search: [10, 20]
      learning_starts: 80
      gamma: 0.99
      beta: 0.5
      double_q: True
      epsilon_initial: 0.5
      epsilon_iterations: 1500
      epsilon_final: 0.01
      replay_alpha: 0.6
      replay_epsilon: 0.01
      replay_eta:
        grid_search: [0.1, 0.5, 0.9]
      replay_beta_iterations: 1500
      buffer_size:
        grid_search: [16384, 32768]
      dueling: True
      model: lstm
      model_config:
        hidden_size: 128
        hidden_layers: 1
      lr: 
        grid_search: [0.001, 0.01]